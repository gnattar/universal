%
% SP 2011 Jan
%
% This will cleanup after a bunch of single-runs to then write postprocessing on 
%  bagger output
%
% USAGE:
% 
% bagger_par_wrapup(params)
%
%   params.baseDataFile: where variables like orig_x, etc. are stored
%   params.execMode: 'encoderRF': process output of encoderRF instances
%   params.tempOutputFiles: wildcard idnicating path to temporary files
%     generated by bagger_par_singlerun
%   parmas.fileToSave: actual output of bagger (resultsFull e.g.)
%
function bagger_par_wrapup(params)
  % 1) load the baseDataFile
	load(params.baseDataFile);
  optionsTree = params.optionsTree;

	% 2) behavior based on execMode ...
	disp(['bagger_par_wrapup::exec mode ' params.execMode]);
	switch (params.execMode)
	  case 'encoderRF' % we know this means single neuron per file
		  
			% compile file list and then prebuild new output matrices
		  fl = dir(params.tempOutputFiles);
			tempDir = fileparts(params.tempOutputFiles);
			neuronsList = nan*zeros(1,length(fl));

      % sizing from diego
      N_neurons = size(orig_y,1);
			N_trial = size(x,2);
			N_time = size(x,3);
			N_feat = size(x,1);

			% setup matrices you will need
      y_zscore_predict = zeros(N_trial*N_time,N_neurons);
      y_zscore_predict_trial = zeros(N_neurons, N_trial, N_time);
      y_predict = zeros(N_trial*N_time,N_neurons);
      y_predict_trial = zeros(N_neurons, N_trial, N_time);

		  % loop thru the temp files and gather the output from singleton runs
			for f=1:length(fl)
			  fn = [tempDir filesep fl(f).name];
			  disp(['bagger_par_wrapup::processing temp file ' fn]);

        % pull out results and grab neuron #
				rf = load(fn); 
				ni = rf.ni;
				rf = rf.results;
				neuronsList(ni) = rf.parameters.neuronsList;

				if (f == 1) % first file, prep everything
				  results = rf; 
				end

				% stuff the matrices hohoho
        y_zscore_predict(:,ni) = rf.y_zscore_predict;
        y_predict(:,ni) = rf.y_predict;
				y_zscore_predict_trial(ni,:,:) = rf.y_zscore_predict_trial(1,:,:);
				y_predict_trial(ni,:,:) = rf.y_predict_trial(1,:,:);
			 
			  % delete it ...
				disp(['DELETE ' fn]);
        delete(fn);
			end

			% grab what is valid ...
			valNeuronsIdx = find(~isnan(neuronsList));
			neuronsList = neuronsList(~isnan(neuronsList));
	
      % assign the matrices
			results.y_zscore_predict_trial = y_zscore_predict_trial(valNeuronsIdx,:,:);
			results.y_predict_trial = y_predict_trial(valNeuronsIdx,:,:);
			results.y_zscore_predict = y_zscore_predict(:,valNeuronsIdx);
			results.y_predict = y_predict(:,valNeuronsIdx);

			% global updates ...
			results.parameters.neuronsList = neuronsList;
			results.parameters.nNeurons = length(neuronsList);

			% things left alone:
      % results.zscore -- this is based on the data and is a normalization factor ; 
			%  should be same regardless of which neuron you process

      % now run the analysis
		  results = getPSTHMultipleGo (orig_x,orig_y,orig_names,'trial_class','', ...
			  optionsTree.minTrials,results);  
   		results= getMetricsEncoder (orig_x,orig_y,y_train,orig_names,'trial_class', ...
			  '', optionsTree.minTrials,results);
	  	results.parameters.encoderFeature.all = names;
	  	results.parameters.encoderFeature.original = orig_names;
  		save(params.fileToSave,'results');

	  case 'getCategoryFeatureTree' % groups of features, again 1 neuron /file
		  
			% compile file list and then prebuild new output matrices
		  fl = dir(params.tempOutputFiles);
			tempDir = fileparts(params.tempOutputFiles);
			neuronsList = nan*zeros(1,length(fl));

      % sizing from diego
      N_neurons = size(orig_y,1);
			N_trial = size(x,2);
			N_time = size(x,3);
			N_feat = size(x,1);

			% setup matrices you will need
      y_zscore_predict = zeros(N_trial*N_time,N_neurons);
      y_zscore_predict_trial = zeros(N_neurons, N_trial, N_time);
      y_predict = zeros(N_trial*N_time,N_neurons);
      y_predict_trial = zeros(N_neurons, N_trial, N_time);

		  % loop thru the temp files and gather the output from singleton runs
			for f=1:length(fl)
			  fn = [tempDir filesep fl(f).name];
			  disp(['bagger_par_wrapup::processing temp file ' fn]);

        % pull out results and grab neuron #
				rf = load(fn); 
				ni = rf.ni;
				rf = rf.results;
				neuronsList(ni) = rf.parameters.neuronsList;

				if (f == 1) % first file, prep everything
				  results = rf; 
				end

				% stuff the matrices hohoho
        y_zscore_predict(:,ni) = rf.y_zscore_predict;
        y_predict(:,ni) = rf.y_predict;
				y_zscore_predict_trial(ni,:,:) = rf.y_zscore_predict_trial(1,:,:);
				y_predict_trial(ni,:,:) = rf.y_predict_trial(1,:,:);
			end

			for f=1:length(fl)
			  fn = [tempDir filesep fl(f).name];
			  % delete it ...
				disp(['DELETE ' fn]);
        delete(fn);
			end

			% grab what is valid ...
			valNeuronsIdx = find(~isnan(neuronsList));
			neuronsList = neuronsList(~isnan(neuronsList));
	
      % assign the matrices
			results.y_zscore_predict_trial = y_zscore_predict_trial(valNeuronsIdx,:,:);
			results.y_predict_trial = y_predict_trial(valNeuronsIdx,:,:);
			results.y_zscore_predict = y_zscore_predict(:,valNeuronsIdx);
			results.y_predict = y_predict(:,valNeuronsIdx);

			% global updates ...
			results.parameters.neuronsList = neuronsList;
			results.parameters.nNeurons = length(neuronsList);

			% things left alone:
      % results.zscore -- this is based on the data and is a normalization factor ; 
			%  should be same regardless of which neuron you process

      % now run the analysis
		  results = getPSTHMultipleGo (orig_x,orig_y,orig_names,'trial_class','', ...
			  optionsTree.minTrials,results);  
   		results= getMetricsEncoder (orig_x,orig_y,y_train,orig_names,'trial_class', ...
			  '', optionsTree.minTrials,results);

			results.parameters.encoderFeatures.all = reGroupName;
			results.parameters.encoderFeatures.groups = regroups;
			results.parameters.encoderFeatures.activeFeatures = params.singleGroup;
			results.parameters.encoderFeatures.categoryNames = reGroupCategory;

  		save(params.fileToSave,'results');

		case 'decoderSingleCellSingleFeature' % single cell decoder - gather all cells, 1 feature
			namesDecoded = params.namesDecoded;

			x = orig_x;
			names = orig_names;
			N_shifts = length(optionsTree.decoder.calciumShifts);

		  fl = dir(params.tempOutputFiles);
			tempDir = fileparts(params.tempOutputFiles);
			for f=1:length(fl)
			  fn = [tempDir filesep fl(f).name];
			  disp(['bagger_par_wrapup::processing temp file ' fn]);

        % pull out results and grab neuron #
				rss = load(fn); 
				resultsSingleCell = rss.resultsSingleCell;
				ni = rss.ni;

				resultsSingleCell.singleNeuron = getPSTHDecoderMultipleGo (x,names, ...
						namesDecoded,'trial_class','',optionsTree.minTrials,resultsSingleCell.parameters.listFeatures, ...
						resultsSingleCell.singleNeuron);
				resultsSingleCell.singleNeuron = getMetricsDecoder (x,names,namesDecoded,'trial_class','', ... 
				  optionsTree.minTrials,resultsSingleCell.parameters.listFeatures, ...
				  resultsSingleCell.singleNeuron);   
				results{ni} = resultsSingleCell;
        
      
    	end

			save(params.fileToSave,'results');
      
      % delete temp files
      for f=1:length(fl);
			  fn = [tempDir filesep fl(f).name];
				disp(['DELETE ' fn]);
        delete(fn);
      end

		case 'touchDecoderSingleCellSingleFeature' % single cell touch decoder -- put all cells in 1 file
			for nrn=1:length(params.neuronIdx)
			  fn = strrep(params.sourceFilename, '%nrn%', num2str(nrn));
			  disp(['bagger_par_wrapup::processing file ' fn]);

        % pull out results and grab neuron #
				rss = load(fn,'-mat'); 
				resultsSingleCell = rss.resultsSingleCell;
				results{nrn} = resultsSingleCell;
    	end

			save(params.fileToSave,'results');
	end
